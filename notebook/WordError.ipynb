{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os,sys\r\n",
    "import pandas as pd\r\n",
    "import pickle\r\n",
    "sys.path.append(os.path.abspath(os.path.join('../scripts')))\r\n",
    "from wer import calculate_wer\r\n",
    "\r\n",
    "from Models import cnn_rnn_model,simple_rnn,model_2,bidirectional_rnn_model_gpu,bidirectional_rnn_model\r\n",
    "from Batch import Batch\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data=pd.read_json('../artifacts/meta.json')\r\n",
    "data.drop(data[data[\"text\"].str.contains(\"\"\"[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~1234567890]\"\"\", na=False)].index,inplace=True)\r\n",
    "with open('../artifacts/features.pkl','rb') as tel:\r\n",
    "    features=pickle.load(tel)\r\n",
    "    tel.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "valid_data=pd.read_json(\"../artifacts/valid_meta.json\")\r\n",
    "valid_data.drop(valid_data[valid_data[\"text\"].str.contains(\"\"\"[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~1234567890]\"\"\", na=False)].index,inplace=True)\r\n",
    "with open('../artifacts/valid_features.pkl','rb') as val:\r\n",
    "    valid_features=pickle.load(val)\r\n",
    "    val.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "FEATURES_LIST=features\r\n",
    "\r\n",
    "TEXT_LIST=data[\"text\"].to_numpy()\r\n",
    "\r\n",
    "FEATURES_VALID_LIST=valid_features\r\n",
    "\r\n",
    "TEXT_VALID_LIST=valid_data[\"text\"].to_numpy()\r\n",
    "MINI_BATCH_SIZE=250\r\n",
    "\r\n",
    "\r\n",
    "audio_gen = Batch(FEATURES_LIST,FEATURES_VALID_LIST,TEXT_LIST,TEXT_VALID_LIST,MINI_BATCH_SIZE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "bidirectional_rnn=bidirectional_rnn_model_gpu(input_dim=26, \r\n",
    "                        units=250)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       [(None, None, 26)]        0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 500)         417000    \n",
      "_________________________________________________________________\n",
      "norm_bidir_rnn (BatchNormali (None, None, 500)         2000      \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, None, 29)          14529     \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, None, 29)          0         \n",
      "=================================================================\n",
      "Total params: 433,529\n",
      "Trainable params: 432,529\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "cnn_rnn = cnn_rnn_model(input_dim=26, # change to 13 if you would like to use MFCC features\r\n",
    "                        filters=250,\r\n",
    "                        kernel_size=4, \r\n",
    "                        conv_stride=1,\r\n",
    "                        conv_border_mode='same',\r\n",
    "                        units=200,output_dim=29)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       [(None, None, 26)]        0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 250)         26250     \n",
      "_________________________________________________________________\n",
      "bn_conv_1d (BatchNormalizati (None, None, 250)         1000      \n",
      "_________________________________________________________________\n",
      "rnn (SimpleRNN)              (None, None, 200)         90200     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, None, 200)         800       \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 29)          5829      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, None, 29)          0         \n",
      "=================================================================\n",
      "Total params: 124,079\n",
      "Trainable params: 123,179\n",
      "Non-trainable params: 900\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "deep_speech = model_2(input_dim=26,\r\n",
    "                filters=100,\r\n",
    "                kernel_size=4, \r\n",
    "                conv_stride=1,\r\n",
    "                conv_border_mode='valid',\r\n",
    "                units=250,\r\n",
    "                activation='tanh',\r\n",
    "                dropout_rate=0.2,\r\n",
    "                number_of_layers=2,\r\n",
    "                output_dim=29)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       [(None, None, 26)]        0         \n",
      "_________________________________________________________________\n",
      "layer_1_conv (Conv1D)        (None, None, 100)         10500     \n",
      "_________________________________________________________________\n",
      "conv_batch_norm (BatchNormal (None, None, 100)         400       \n",
      "_________________________________________________________________\n",
      "rnn_1 (GRU)                  (None, None, 250)         264000    \n",
      "_________________________________________________________________\n",
      "bt_rnn_1 (BatchNormalization (None, None, 250)         1000      \n",
      "_________________________________________________________________\n",
      "final_layer_of_rnn (GRU)     (None, None, 250)         376500    \n",
      "_________________________________________________________________\n",
      "bt_rnn_final (BatchNormaliza (None, None, 250)         1000      \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, None, 29)          7279      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, None, 29)          0         \n",
      "=================================================================\n",
      "Total params: 660,679\n",
      "Trainable params: 659,479\n",
      "Non-trainable params: 1,200\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "with open('models\\\\bidirectional_rnn_gpu.h5', 'rb') as t:\r\n",
    "        bidirectional_rnn_model_hist=pickle.load( t)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "with open('models\\\\deep_speech.pickle', 'rb') as f:\r\n",
    "        deep_speech_hist=pickle.load( f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "with open('models\\\\simple_rnn_model.pickle', 'rb') as g:\r\n",
    "        cnn_hist=pickle.load( g)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "with open('models\\cnn_rnn.h5', 'rb') as g:\r\n",
    "        cnn_hist=pickle.load( g)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "cnn_rnn.load_weights('./model/cnn.h5')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "deep_speech.load_weights('./model/deep.h5')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from wer import predict"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "predict(audio_gen,4,'validation',deep_speech)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Truth: wanaeleza kupoteza maisha baada ya kutokea kwa mlipuko mwingine wa gesi\n",
      "Predicted: waleleta kuputeka maishaba ya kutokea kwa mipokumenjini wajiefi\n",
      "wer: 20\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "predict(audio_gen,4,'validation',cnn_rnn)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Truth: wanaeleza kupoteza maisha baada ya kutokea kwa mlipuko mwingine wa gesi\n",
      "Predicted: wanelewa kuotena maisha ba ya kutoea wamipoungini wapi\n",
      "wer: 22\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "predict(audio_gen,17,'validation',deep_speech)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Truth: ulitokea mapema siku ya ijumaa\n",
      "Predicted: ulitoteamapemashikulevyuma\n",
      "wer: 11\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "wer="
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-dbaf8c1a3d06>, line 1)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-19-dbaf8c1a3d06>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    wer=\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import importlib \r\n",
    "import wer2\r\n",
    "importlib.reload(wer2)\r\n",
    "from wer2 import calculate_wer_entire,make_predictions"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "from tensorflow.keras.models import load_model,save_model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "deep2=load_model('deep_speech_model_l.h5')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "save_model(deep_speech,\"deep_speech_model_l.h5\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "make_predictions(deep_speech,[valid_features[0]])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['barendali yvemekoter we hedia koreakuspili kueiparili kwa a datikadini']"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "calculate_wer_entire(deep_speech,valid_features,valid_data[\"text\"].tolist())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9102984399728691"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "calculate_wer_entire(cnn_rnn,valid_features,valid_data[\"text\"].tolist())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9691951164368076"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "3ebe1e15dab481e38dbc50cacd21ed8ec6b22a54b0f3cb3b993bb569cf9c8bed"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}